{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1213da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuel/Documents/JPMC_PythonProjects/AgenticAIWorkspace/ClientReferenceAgent/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Company Name Resolution using ReAct Agent\n",
    "Identifies and maps company names from user queries to database entries.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from typing import List, Dict, Optional, Tuple, Set\n",
    "from collections import defaultdict\n",
    "import unicodedata\n",
    "\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from rapidfuzz import fuzz\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "# /Users/samuel/Documents/JPMC_PythonProjects/AgenticAIWorkspace/ClientReferenceAgent/run_agent_v2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "095c7269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from openai import OpenAI\n",
    "\n",
    "# # Assumes OPENAI_API_KEY environment variable is set\n",
    "# client = OpenAI()\n",
    "\n",
    "# response = client.embeddings.create(\n",
    "#     input=\"<company name>\",\n",
    "#     model=\"text-embedding-3-small\" # or \"text-embedding-3-large\"\n",
    "# )\n",
    "\n",
    "# # # The embedding is a list of floating point numbers\n",
    "# # embedding = response.data[0].embedding\n",
    "# # print(f\"Embedding length: {len(embedding)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98f91126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Central configuration\"\"\"\n",
    "    OPENAI_MODEL = \"gpt-4o-mini\"\n",
    "    MAX_ITERATIONS = 10\n",
    "    # EMBEDDINGS_AVAILABLE = True\n",
    "    \n",
    "    # Company suffixes to normalize\n",
    "    COMPANY_SUFFIXES = [\n",
    "        \"Inc.\", \"Inc\", \"LLC\", \"L.L.C.\", \"LP\", \"L.P.\", \n",
    "        \"Ltd.\", \"Ltd\", \"Limited\", \"Corporation\", \"Corp.\", \"Corp\",\n",
    "        \"Associates\", \"Advisors\", \"Management\", \"Partners\",\n",
    "        \"Investments\", \"Capital\", \"Group\", \"Authority\"\n",
    "    ]\n",
    "    \n",
    "    # # Nickname mappings\n",
    "    # NICKNAME_MAPPING = {\n",
    "    #     \"2sigma\": \"Two Sigma Investments, LP\",\n",
    "    #     \"apple\": \"Apple Inc.\", \n",
    "    #     \"google\": \"Alphabet Inc.\",\n",
    "    #     \"aapl\": \"Apple Inc.\",\n",
    "    #     \"googl\": \"Alphabet Inc.\"\n",
    "    # }\n",
    "\n",
    "    NICKNAME_MAPPING = {\n",
    "    # Entity blocks (one nickname -> multiple companies)\n",
    "    \"millennium\": [\n",
    "        \"Millennium Partners\", \n",
    "        \"Millennium Management LLC\"\n",
    "    ],\n",
    "    \"bridge\": [\"Bridge Associates\"],\n",
    "    \"bridgewater\": [\"Bridgewater Associates\"],\n",
    "    \"bridger\": [\"Bridger Capital\"],\n",
    "    \"2sigma\": [\"Two Sigma Investments, LP\"],\n",
    "    \"googl\": [\"Alphabet Inc.\"],\n",
    "    \"bridgewater\": [\"Bridgewater Associates\"],\n",
    "    \"adia\": [\"Abu Dhabi Investment Authority\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6017a141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DATA SETUP\n",
    "# ============================================================================\n",
    "\n",
    "def initialize_company_database() -> pd.DataFrame:\n",
    "    \"\"\"Initialize the company database\"\"\"\n",
    "    data = {\n",
    "        'Company': [\n",
    "            \"Apple Inc.\", \n",
    "            \"Two Sigma Investments, LP\", \n",
    "            \"Millennium Partners\", \n",
    "            \"Millennium Management LLC\", \n",
    "            \"WorldQuant Millennium Advisors\",\n",
    "            \"Bridge Associates\", \n",
    "            \"Bridgewater Associates\",\n",
    "            \"Bridger Capital\",\n",
    "            \"Curry's Retail Ltd.\",\n",
    "            \"Alphabet Inc.\",\n",
    "            \"Abu Dhabi Investment Authority\"\n",
    "        ]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# def initialize_embeddings(companies: List[str]):\n",
    "#     \"\"\"Initialize embedding model for semantic similarity\"\"\"\n",
    "#     try:\n",
    "#         model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "#         embeddings = model.encode(companies)\n",
    "#         print(\"✓ Embedding model loaded\")\n",
    "#         return model, embeddings\n",
    "#     except Exception as e:\n",
    "#         print(f\"⚠ Could not load embedding model: {e}\")\n",
    "#         return None, None\n",
    "    \n",
    "\n",
    "# def initialize_embeddings(companies: List[str], openai_client=None):\n",
    "#     \"\"\"Initialize embedding model for semantic similarity\"\"\"\n",
    "#     try:\n",
    "#         if openai_client:\n",
    "#             # Use OpenAI embeddings\n",
    "#             print(\"Generating OpenAI embeddings...\")\n",
    "#             response = openai_client.embeddings.create(\n",
    "#                 input=companies,\n",
    "#                 model=\"text-embedding-3-small\"\n",
    "#             )\n",
    "#             embeddings = np.array([item.embedding for item in response.data])\n",
    "#             print(\"✓ OpenAI embeddings loaded\")\n",
    "#             return None, embeddings  # No model needed, just embeddings\n",
    "#         # else:\n",
    "#         #     # Fallback to sentence-transformers (if you want to keep it)\n",
    "#         #     model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "#         #     embeddings = model.encode(companies)\n",
    "#         #     print(\"✓ Embedding model loaded\")\n",
    "#         #     return model, embeddings\n",
    "#     except Exception as e:\n",
    "#         print(f\"⚠ Could not load embedding model: {e}\")\n",
    "#         return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "712c7319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FAST FUZZY MATCHER\n",
    "# ============================================================================\n",
    "\n",
    "class FastFuzzyMatcher:\n",
    "    \"\"\"High-performance fuzzy string matcher with multiple matching strategies\"\"\"\n",
    "    \n",
    "    def __init__(self, company_data: List[Tuple[str, str]]):\n",
    "        \"\"\"\n",
    "        Initialize matcher with company data.\n",
    "        \n",
    "        Args:\n",
    "            company_data: List of tuples (company_id, company_name)\n",
    "        \"\"\"\n",
    "        self.company_data = company_data\n",
    "        self.normalized_names = []\n",
    "        self.original_names = []\n",
    "        self.company_ids = []\n",
    "        self.word_to_companies = defaultdict(set)\n",
    "        self.trigram_to_companies = defaultdict(set)\n",
    "        \n",
    "        self._build_indexes()\n",
    "    \n",
    "    def _normalize_string(self, s: str) -> str:\n",
    "        \"\"\"Normalize string for better matching\"\"\"\n",
    "        s = s.lower()\n",
    "        # Remove accents\n",
    "        s = unicodedata.normalize('NFKD', s)\n",
    "        s = ''.join(c for c in s if not unicodedata.combining(c))\n",
    "        # Remove common suffixes and punctuation\n",
    "        s = re.sub(r'\\b(llc|ltd|corp|inc)\\b', '', s)\n",
    "        s = re.sub(r'[^\\w\\s]', '', s)\n",
    "        s = re.sub(r'\\s+', ' ', s).strip()\n",
    "        return s\n",
    "    \n",
    "    def _get_trigrams(self, s: str) -> Set[str]:\n",
    "        \"\"\"Generate trigrams from string\"\"\"\n",
    "        s = f\"  {s}  \"  # Add padding\n",
    "        return {s[i:i+3] for i in range(len(s) - 2)}\n",
    "    \n",
    "    def _build_indexes(self):\n",
    "        \"\"\"Build word and trigram indexes for fast lookup\"\"\"\n",
    "        for i, (company_id, company_name) in enumerate(self.company_data):\n",
    "            normalized = self._normalize_string(company_name)\n",
    "            self.normalized_names.append(normalized)\n",
    "            self.original_names.append(company_name)\n",
    "            self.company_ids.append(company_id)\n",
    "            \n",
    "            # Word index\n",
    "            words = normalized.split()\n",
    "            for word in words:\n",
    "                if len(word) >= 2:\n",
    "                    self.word_to_companies[word].add(i)\n",
    "            \n",
    "            # Trigram index\n",
    "            trigrams = self._get_trigrams(normalized)\n",
    "            for trigram in trigrams:\n",
    "                self.trigram_to_companies[trigram].add(i)\n",
    "\n",
    "\n",
    "    def _word_similarity_with_position(self, query_words: List[str], target_words: List[str]) -> float:\n",
    "        \"\"\"\n",
    "        Calculate word-based similarity with position and prefix awareness.\n",
    "        This ensures \"Millennium\" ranks \"Millennium Partners\" higher than \n",
    "        \"WorldQuant Millennium Advisors\"\n",
    "        \"\"\"\n",
    "        if not query_words or not target_words:\n",
    "            return 0.0\n",
    "        \n",
    "        query_set = set(query_words)\n",
    "        target_set = set(target_words)\n",
    "        \n",
    "        # Base score: exact word matches\n",
    "        exact_matches = len(query_set & target_set)\n",
    "        \n",
    "        # Position bonus: same word at same position\n",
    "        position_matches = 0\n",
    "        for i, q_word in enumerate(query_words):\n",
    "            if i < len(target_words) and q_word == target_words[i]:\n",
    "                position_matches += 1\n",
    "        \n",
    "        # Prefix match: first word of query matches first word of target\n",
    "        prefix_match = 1.0 if (query_words and target_words and query_words[0] == target_words[0]) else 0.0\n",
    "        \n",
    "        \n",
    "        # Partial matches (substring)\n",
    "        partial_matches = 0\n",
    "        for q_word in query_words:\n",
    "            for t_word in target_words:\n",
    "                if q_word != t_word and (q_word in t_word or t_word in q_word):\n",
    "                    partial_matches += 0.5\n",
    "                    break\n",
    "        \n",
    "        max_words = max(len(query_words), len(target_words))\n",
    "        \n",
    "        # Weighted scoring\n",
    "        base_score = (exact_matches + partial_matches) / max_words\n",
    "        position_score = position_matches / max_words\n",
    "        \n",
    "        # Weighted combination (weights sum to 1.0)\n",
    "        # - 50% base matching - \"Do the words appear at all?\" This is most fundamental\n",
    "        # - 30% prefix matching - Company names usually start with the key identifier (\"Millennium Partners\", \"Goldman Sachs\")\n",
    "        # - 20% position matching - Word order matters, but less than presence and prefix\n",
    "        final_score = (0.5 * base_score) + (0.3 * prefix_match) + (0.2 * position_score)\n",
    "        return final_score\n",
    "    \n",
    "    \n",
    "    # def _word_similarity(self, query_words: List[str], target_words: List[str]) -> float:\n",
    "    #     \"\"\"Calculate word-based similarity\"\"\"\n",
    "    #     if not query_words or not target_words:\n",
    "    #         return 0.0\n",
    "        \n",
    "    #     query_set = set(query_words)\n",
    "    #     target_set = set(target_words)\n",
    "        \n",
    "    #     # Exact matches\n",
    "    #     exact_matches = len(query_set & target_set)\n",
    "        \n",
    "    #     # Partial matches (substring)\n",
    "    #     partial_matches = 0\n",
    "    #     for q_word in query_words:\n",
    "    #         for t_word in target_words:\n",
    "    #             if q_word != t_word and (q_word in t_word or t_word in q_word):\n",
    "    #                 partial_matches += 0.5\n",
    "    #                 break\n",
    "        \n",
    "    #     max_words = max(len(query_words), len(target_words))\n",
    "    #     return (exact_matches + partial_matches) / max_words\n",
    "    \n",
    "    def _jaccard_similarity(self, set1: Set[str], set2: Set[str]) -> float:\n",
    "        \"\"\"Calculate Jaccard similarity\"\"\"\n",
    "        if not set1 and not set2:\n",
    "            return 1.0\n",
    "        if not set1 or not set2:\n",
    "            return 0.0\n",
    "        intersection = len(set1 & set2)\n",
    "        union = len(set1 | set2)\n",
    "        return intersection / union\n",
    "    \n",
    "    def _calculate_similarity(self, query: str, target_idx: int) -> float:\n",
    "        \"\"\"Calculate overall similarity score\"\"\"\n",
    "        query_normalized = self._normalize_string(query)\n",
    "        target_normalized = self.normalized_names[target_idx]\n",
    "        \n",
    "        # Exact match\n",
    "        if query_normalized == target_normalized:\n",
    "            return 1.0\n",
    "        \n",
    "        # Substring match\n",
    "        if query_normalized in target_normalized or target_normalized in query_normalized:\n",
    "            return 0.95\n",
    "        \n",
    "        query_words = query_normalized.split()\n",
    "        target_words = target_normalized.split()\n",
    "        \n",
    "        # Word similarity (for exact word matches)\n",
    "        word_sim = self._word_similarity_with_position(query_words, target_words)\n",
    "        \n",
    "        # Trigram similarity (for fuzzy/spelling variations)\n",
    "        query_trigrams = self._get_trigrams(query_normalized)\n",
    "        target_trigrams = self._get_trigrams(target_normalized)\n",
    "        trigram_sim = self._jaccard_similarity(query_trigrams, target_trigrams)\n",
    "        \n",
    "        # Character-level edit distance ratio\n",
    "        min_len = min(len(query_normalized), len(target_normalized))\n",
    "        max_len = max(len(query_normalized), len(target_normalized))\n",
    "        length_ratio = min_len / max_len if max_len > 0 else 0\n",
    "        \n",
    "        # Use rapidfuzz for additional measure\n",
    "        from rapidfuzz import fuzz\n",
    "        partial_ratio = fuzz.partial_ratio(query_normalized, target_normalized) / 100.0\n",
    "        token_sort_ratio = fuzz.token_sort_ratio(query_normalized, target_normalized) / 100.0\n",
    "        \n",
    "        # Adaptive weighted combination\n",
    "        if word_sim < 0.3:  # Poor word match - likely spelling variation\n",
    "            # Rely heavily on character-level matching\n",
    "            score = 0.1 * word_sim + 0.3 * trigram_sim + 0.2 * length_ratio + 0.2 * partial_ratio + 0.2 * token_sort_ratio\n",
    "        else:  # Good word match\n",
    "            score = 0.5 * word_sim + 0.2 * trigram_sim + 0.1 * length_ratio + 0.1 * partial_ratio + 0.1 * token_sort_ratio\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    # def _calculate_similarity(self, query: str, target_idx: int) -> float:\n",
    "    #     \"\"\"Calculate overall similarity score\"\"\"\n",
    "    #     query_normalized = self._normalize_string(query)\n",
    "    #     target_normalized = self.normalized_names[target_idx]\n",
    "        \n",
    "    #     # Exact match\n",
    "    #     if query_normalized == target_normalized:\n",
    "    #         return 1.0\n",
    "        \n",
    "    #     # Substring match\n",
    "    #     if query_normalized in target_normalized or target_normalized in query_normalized:\n",
    "    #         return 0.95\n",
    "        \n",
    "    #     query_words = query_normalized.split()\n",
    "    #     target_words = target_normalized.split()\n",
    "        \n",
    "    #     # Word similarity (weighted heavily for business names)\n",
    "    #     word_sim = self._word_similarity(query_words, target_words)\n",
    "        \n",
    "    #     # Trigram similarity\n",
    "    #     query_trigrams = self._get_trigrams(query_normalized)\n",
    "    #     target_trigrams = self._get_trigrams(target_normalized)\n",
    "    #     trigram_sim = self._jaccard_similarity(query_trigrams, target_trigrams)\n",
    "        \n",
    "    #     # Weighted combination\n",
    "    #     return 0.7 * word_sim + 0.3 * trigram_sim\n",
    "    \n",
    "    def find_matches(self, query: str, top_n: int = 10, min_score: float = 0.25) -> List[Tuple[str, str, float]]:\n",
    "        \"\"\"\n",
    "        Find top N matches for the query.\n",
    "        \n",
    "        Args:\n",
    "            query: Search string\n",
    "            top_n: Number of top matches to return\n",
    "            min_score: Minimum similarity score threshold\n",
    "        \n",
    "        Returns:\n",
    "            List of tuples (company_id, company_name, similarity_score)\n",
    "        \"\"\"\n",
    "        if not query.strip():\n",
    "            return []\n",
    "        \n",
    "        query_normalized = self._normalize_string(query)\n",
    "        query_words = set(query_normalized.split())\n",
    "        query_trigrams = self._get_trigrams(query_normalized)\n",
    "\n",
    "        # print(f\"  [MATCHER DEBUG] Query normalized: '{query_normalized}'\")\n",
    "        # print(f\"  [MATCHER DEBUG] Query words: {query_words}\")\n",
    "        # print(f\"  [MATCHER DEBUG] Query trigrams count: {len(query_trigrams)}\")\n",
    "        # print(f\"  [MATCHER DEBUG] Sample trigrams: {list(query_trigrams)[:10]}\")\n",
    "        \n",
    "        \n",
    "        # Gather candidates\n",
    "        candidate_indices = set()\n",
    "        \n",
    "        # Word-based candidates\n",
    "        for word in query_words:\n",
    "            if word in self.word_to_companies:\n",
    "                candidate_indices.update(self.word_to_companies[word])\n",
    "\n",
    "        # print(f\"  [MATCHER DEBUG] Word-based candidates: {len(candidate_indices)}\")\n",
    "        \n",
    "        # Trigram-based candidates\n",
    "        trigram_matches = defaultdict(int)\n",
    "        for trigram in query_trigrams:\n",
    "            if trigram in self.trigram_to_companies:\n",
    "                for idx in self.trigram_to_companies[trigram]:\n",
    "                    trigram_matches[idx] += 1\n",
    "\n",
    "        # print(f\"  [MATCHER DEBUG] Trigram matches: {len(trigram_matches)} companies\")\n",
    "        if trigram_matches:\n",
    "            top_3 = sorted(trigram_matches.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "            # print(f\"  [MATCHER DEBUG] Top 3 trigram matches: {[(self.original_names[idx], count) for idx, count in top_3]}\")\n",
    "        \n",
    "        # Add candidates with sufficient trigram overlap\n",
    "        min_trigram_matches = max(1, len(query_trigrams) // 4)\n",
    "        # print(f\"  [MATCHER DEBUG] Min trigram threshold: {min_trigram_matches}\")\n",
    "        for idx, count in trigram_matches.items():\n",
    "            if count >= min_trigram_matches:\n",
    "                candidate_indices.add(idx)\n",
    "\n",
    "        # print(f\"  [MATCHER DEBUG] After trigram filter: {len(candidate_indices)} candidates\")\n",
    "\n",
    "        # If we have very few candidates from indexing, expand search\n",
    "        if len(candidate_indices) < 5:\n",
    "            # Add top trigram matches even if below threshold\n",
    "            top_trigram_candidates = sorted(trigram_matches.items(), \n",
    "                                           key=lambda x: x[1], \n",
    "                                           reverse=True)[:20]\n",
    "            for idx, _ in top_trigram_candidates:\n",
    "                candidate_indices.add(idx)\n",
    "            # print(f\"  [MATCHER DEBUG] Expanded to {len(candidate_indices)} candidates\")\n",
    "        \n",
    "        \n",
    "        # Fallback: if still no candidates, check all (for very short queries or edge cases)\n",
    "        if not candidate_indices:\n",
    "            candidate_indices = set(range(len(self.company_data)))\n",
    "            # print(f\"  [MATCHER DEBUG] Fallback: checking all {len(candidate_indices)} companies\")\n",
    "        \n",
    "        \n",
    "        # Calculate similarity scores\n",
    "        scored_candidates = []\n",
    "        for idx in candidate_indices:\n",
    "            score = self._calculate_similarity(query, idx)\n",
    "            if score >= min_score:\n",
    "                scored_candidates.append((\n",
    "                    self.company_ids[idx],\n",
    "                    self.original_names[idx],\n",
    "                    score\n",
    "                ))\n",
    "\n",
    "        \n",
    "        # print(f\"  [MATCHER DEBUG] Scored candidates above threshold: {len(scored_candidates)}\")\n",
    "        # if scored_candidates:\n",
    "        #     print(f\"  [MATCHER DEBUG] Top scored: {scored_candidates[0]}\")\n",
    "        \n",
    "        \n",
    "        # Sort and return top N\n",
    "        scored_candidates.sort(key=lambda x: x[2], reverse=True)\n",
    "        return scored_candidates[:top_n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "887cbcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TOOL IMPLEMENTATIONS\n",
    "# ============================================================================\n",
    "\n",
    "class CompanyResolutionTools:\n",
    "    \"\"\"Collection of tools for company name resolution\"\"\"\n",
    "    \n",
    "    def __init__(self, client: OpenAI, matcher: FastFuzzyMatcher):\n",
    "        self.client = client\n",
    "        self.matcher = matcher\n",
    "    \n",
    "    def extract_names(self, query: str) -> str:\n",
    "        \"\"\"Extract, correct, and expand company names from user query using LLM\"\"\"\n",
    "        prompt = f\"\"\"Extract all potential company names from this user query: \"{query}\"\n",
    "\n",
    "                For each company name found, provide:\n",
    "                1. The original name as it appears in the query (preserve exact formatting)\n",
    "                2. A spelling-corrected version (fix typos, remove extraneous punctuation)\n",
    "                3. An expanded version if it's an abbreviation/acronym/commonly used shortform (otherwise same as corrected)\n",
    "\n",
    "                Note: Don't worry about capitalization - focus on spelling and expansion.\n",
    "\n",
    "                Return a JSON object with this structure:\n",
    "                {{\n",
    "                \"companies\": [\n",
    "                    {{\n",
    "                    \"original\": \"the exact name from query\",\n",
    "                    \"corrected\": \"spelling-corrected version\",\n",
    "                    \"expanded\": \"full expanded name if abbreviation, otherwise same as corrected\"\n",
    "                    }}\n",
    "                ]\n",
    "                }}\n",
    "\n",
    "                Examples:\n",
    "\n",
    "                Query: \"What is the balance of ADIA' in 2025?\"\n",
    "                Output: {{\n",
    "                \"companies\": [\n",
    "                    {{\n",
    "                    \"original\": \"ADIA'\",\n",
    "                    \"corrected\": \"ADIA\",\n",
    "                    \"expanded\": \"Abu Dhabi Investment Authority\"\n",
    "                    }}\n",
    "                ]\n",
    "                }}\n",
    "\n",
    "                Query: \"Compare ups and Fedex performance\"\n",
    "                Output: {{\n",
    "                \"companies\": [\n",
    "                    {{\n",
    "                    \"original\": \"ups\",\n",
    "                    \"corrected\": \"ups\",\n",
    "                    \"expanded\": \"United Parcel Service\"\n",
    "                    }},\n",
    "                    {{\n",
    "                    \"original\": \"Fedex\",\n",
    "                    \"corrected\": \"FedEx\",\n",
    "                    \"expanded\": \"Federal Express\"\n",
    "                    }}\n",
    "                ]\n",
    "                }}\n",
    "\n",
    "                Query: \"Show data for Microsft and Gogle\"\n",
    "                Output: {{\n",
    "                \"companies\": [\n",
    "                    {{\n",
    "                    \"original\": \"Microsft\",\n",
    "                    \"corrected\": \"Microsoft\",\n",
    "                    \"expanded\": \"Microsoft Corporation\"\n",
    "                    }},\n",
    "                    {{\n",
    "                    \"original\": \"Gogle\",\n",
    "                    \"corrected\": \"Google\",\n",
    "                    \"expanded\": \"Google LLC\"\n",
    "                    }}\n",
    "                ]\n",
    "                }}\n",
    "\n",
    "                Query: \"Show me revenue data\"\n",
    "                Output: {{\n",
    "                \"companies\": []\n",
    "                }}\n",
    "\n",
    "                Return ONLY the JSON object, nothing else.\"\"\"                \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=Config.OPENAI_MODEL,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.0,\n",
    "                max_tokens=300\n",
    "            )\n",
    "            \n",
    "            result = response.choices[0].message.content.strip()\n",
    "            data = json.loads(result)\n",
    "            \n",
    "            # Build ordered lists for each company\n",
    "            companies_with_variants = []\n",
    "            for company in data.get(\"companies\", []):\n",
    "                variants = [\n",
    "                    company[\"original\"],\n",
    "                    company[\"corrected\"],\n",
    "                    company[\"expanded\"]\n",
    "                ]\n",
    "                # Remove duplicates while preserving order\n",
    "                seen = set()\n",
    "                ordered_variants = []\n",
    "                for v in variants:\n",
    "                    if v.lower() not in seen:\n",
    "                        seen.add(v.lower())\n",
    "                        ordered_variants.append(v)\n",
    "                \n",
    "                companies_with_variants.append({\n",
    "                    \"original\": company[\"original\"],\n",
    "                    \"variants\": ordered_variants\n",
    "                })\n",
    "            \n",
    "            return json.dumps({\n",
    "                \"companies\": companies_with_variants,\n",
    "                \"message\": f\"Extracted {len(companies_with_variants)} company name(s) with variants\"\n",
    "            })\n",
    "        except Exception as e:\n",
    "            return json.dumps({\"companies\": [], \"error\": str(e)})\n",
    "    \n",
    "        \n",
    "    def map_nickname(self, candidate_name: str) -> str:\n",
    "        \"\"\"\n",
    "        Map nicknames to official company names.\n",
    "        Now supports entity blocks (one nickname -> multiple companies).\n",
    "        \n",
    "        Args:\n",
    "            candidate_name: The nickname to map (e.g., \"millennium\", \"2sigma\")\n",
    "        \n",
    "        Returns:\n",
    "            JSON string with mapping result\n",
    "        \"\"\"\n",
    "        query_lower = candidate_name.lower().strip()\n",
    "        \n",
    "        if query_lower in Config.NICKNAME_MAPPING:\n",
    "            mapped = Config.NICKNAME_MAPPING[query_lower]\n",
    "            \n",
    "            # Handle both single strings and lists (entity blocks)\n",
    "            if isinstance(mapped, list):\n",
    "                return json.dumps({\n",
    "                    \"is_nickname\": True,\n",
    "                    \"nickname\": candidate_name,\n",
    "                    \"official_names\": mapped,\n",
    "                    \"message\": f\"Mapped identifier '{candidate_name}' to '{mapped}'\"\n",
    "                })\n",
    "        \n",
    "        return json.dumps({\n",
    "            \"is_nickname\": False,\n",
    "            \"message\": f\"'{candidate_name}' is not a recognized nickname\"\n",
    "        }, indent=2)\n",
    "    \n",
    "    def fuzzy_search(self, candidate_name: str, top_n: int = 10, min_score: float = 0.25) -> str:\n",
    "        \"\"\"Find similar company names using fuzzy matching\"\"\"\n",
    "        try:\n",
    "            # Debug: print what we're searching for\n",
    "            print(f\"  [DEBUG] Searching for: '{candidate_name}'\")\n",
    "            print(f\"  [DEBUG] Min score threshold: {min_score}\")\n",
    "            \n",
    "            matches = self.matcher.find_matches(candidate_name, top_n=top_n, min_score=min_score)\n",
    "            print(f\"  [DEBUG] Found {len(matches)} matches\")\n",
    "            if matches:\n",
    "                print(f\"  [DEBUG] Top match: {matches[0]}\")\n",
    "            if not matches:\n",
    "                return json.dumps({\n",
    "                    \"status\": \"no_matches\",\n",
    "                    \"matches\": [],\n",
    "                    \"message\": f\"No matches found for '{candidate_name}'\"\n",
    "                })\n",
    "            \n",
    "            results = {\n",
    "                \"status\": \"success\",\n",
    "                \"query\": candidate_name,\n",
    "                \"total_matches\": len(matches),\n",
    "                \"matches\": [\n",
    "                    {\n",
    "                        \"company_id\": company_id,\n",
    "                        \"company_name\": company_name,\n",
    "                        \"similarity_score\": round(score, 3)\n",
    "                    }\n",
    "                    for company_id, company_name, score in matches\n",
    "                ]\n",
    "            }\n",
    "            return json.dumps(results, indent=2)\n",
    "        except Exception as e:\n",
    "            return json.dumps({\"status\": \"error\", \"message\": str(e)})\n",
    "    \n",
    "        \n",
    "    def disambiguate(self, query: str) -> str:\n",
    "        \"\"\"Disambiguate between multiple candidate companies\"\"\"\n",
    "        try:\n",
    "            # Strip quotes if present\n",
    "            query = query.strip('\"\\'')\n",
    "            \n",
    "            # Handle escaped quotes - sometimes the input comes with escaped quotes\n",
    "            # Try to parse as-is first, if that fails, try replacing escaped quotes\n",
    "            try:\n",
    "                data = json.loads(query)\n",
    "            except json.JSONDecodeError:\n",
    "                # Try unescaping if initial parse fails\n",
    "                query_unescaped = query.replace('\\\\\"', '\"').replace(\"\\\\'\", \"'\")\n",
    "                data = json.loads(query_unescaped)\n",
    "            \n",
    "            candidates = data.get('candidates', [])\n",
    "            original_query = data.get('query', '')\n",
    "            \n",
    "            if not candidates:\n",
    "                return json.dumps({\"selected\": [], \"message\": \"No candidates provided\"})\n",
    "            \n",
    "            candidates_str = '\\n'.join([f\"- {c}\" for c in candidates])\n",
    "            \n",
    "            prompt = f\"\"\"User query: \"{original_query}\"\n",
    "\n",
    "                    Candidate companies from database:\n",
    "                    {candidates_str}\n",
    "\n",
    "                    Determine which company(ies) the user is most likely referring to.\n",
    "\n",
    "                    **Key Rules:**\n",
    "\n",
    "                    1. **Word Order Matters**: Match based on the BEGINNING words of company names\n",
    "                    - \"Millennium\" matches \"Millennium Partners\" and \"Millennium Management LLC\" \n",
    "                    - \"Millennium\" does NOT strongly match \"WorldQuant Millennium Advisors\" (Millennium is not the first word)\n",
    "                    - \"WorldQuant\" matches \"WorldQuant Millennium Advisors\"\n",
    "\n",
    "                    2. **Specificity Determines Selection**:\n",
    "                    - If user term is GENERIC/AMBIGUOUS (matches multiple companies as prefix): return ALL matching companies\n",
    "                        Example: \"Millennium\" → [\"Millennium Partners\", \"Millennium Management LLC\"]\n",
    "                    - If user term is SPECIFIC (uniquely identifies one company): return only that company\n",
    "                        Example: \"WorldQuant\" → [\"WorldQuant Millennium Advisors\"]\n",
    "\n",
    "                    3. **Matching Strategy**:\n",
    "                    - Check if user's term appears as a STARTING word/phrase in the company name\n",
    "                    - Partial matches in later words are lower priority\n",
    "                    - When in doubt about user intent, include all plausible matches\n",
    "\n",
    "                    **Examples:**\n",
    "\n",
    "                    User query: \"Show balance for Millennium\"\n",
    "                    Candidates: [\"Millennium Partners\", \"Millennium Management LLC\", \"WorldQuant Millennium Advisors\"]\n",
    "                    Selected: [\"Millennium Partners\", \"Millennium Management LLC\"]\n",
    "                    Reason: \"Millennium\" may refer to both \"Millennium Partners\", \"Millennium Management LLC\", \n",
    "                            but \"WorldQuant Millennium Advisors\" would have been referred to as \"WorldQuant\".\n",
    "                            Note: The initial terms used to name a company are crucial for identifying a company. \n",
    "\n",
    "                    User query: \"What about WorldQuant?\"\n",
    "                    Candidates: [\"Millennium Partners\", \"Millennium Management LLC\", \"WorldQuant Millennium Advisors\"]\n",
    "                    Selected: [\"WorldQuant Millennium Advisors\"]\n",
    "                    Reason: \"WorldQuant\" specifically identifies one company\n",
    "\n",
    "                    User query: \"Bridge Associates data\"\n",
    "                    Candidates: [\"Bridge Associates\", \"Bridgewater Associates\", \"Bridger Capital\"]\n",
    "                    Selected: [\"Bridge Associates\"]\n",
    "                    Reason: \"Bridge Associates\" is an exact match to a specific company\n",
    "\n",
    "                    Return ONLY a JSON array of selected company names from the candidates list.\n",
    "                    Example: [\"Company Name 1\", \"Company Name 2\"]\n",
    "\n",
    "                    Do not include explanations, markdown, or any other text.\n",
    "                    \"\"\"\n",
    "            try:              \n",
    "                response = self.client.chat.completions.create(\n",
    "                    model=Config.OPENAI_MODEL,\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                    temperature=0.0,\n",
    "                    max_tokens=200\n",
    "                )\n",
    "            \n",
    "                result = response.choices[0].message.content.strip()\n",
    "                print(f\"  [DEBUG] LLM returned: {repr(result)}\")\n",
    "                \n",
    "                # FIXED: Clean up BEFORE parsing\n",
    "                # Remove markdown code blocks\n",
    "                if '```' in result:\n",
    "                    # Extract content between ``` markers\n",
    "                    parts = result.split('```')\n",
    "                    for part in parts:\n",
    "                        part = part.strip()\n",
    "                        if part.startswith('json'):\n",
    "                            part = part[4:].strip()\n",
    "                        if part.startswith('[') and part.endswith(']'):\n",
    "                            result = part\n",
    "                            break\n",
    "                \n",
    "                # Find the JSON array\n",
    "                start_idx = result.find('[')\n",
    "                end_idx = result.rfind(']')\n",
    "                \n",
    "                if start_idx != -1 and end_idx != -1:\n",
    "                    result = result[start_idx:end_idx+1]\n",
    "                \n",
    "                print(f\"  [DEBUG] Cleaned result: {repr(result)}\")\n",
    "\n",
    "                # NOW parse the cleaned result\n",
    "                try:\n",
    "                    selected = json.loads(result)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"  [DEBUG] LLM response parsing failed: {e}\")\n",
    "                    print(f\"  [DEBUG] Falling back to all candidates\")\n",
    "                    # Fallback: return all candidates\n",
    "                    selected = candidates\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  [DEBUG] LLM call failed: {e}\")\n",
    "                # Fallback: return all candidates\n",
    "                selected = candidates\n",
    "            \n",
    "            # Validate and return\n",
    "            # Make sure selected items are actually in candidates\n",
    "            if isinstance(selected, list):\n",
    "                selected = [s for s in selected if s in candidates]\n",
    "            else:\n",
    "                selected = candidates\n",
    "            \n",
    "            if not selected:\n",
    "                selected = candidates\n",
    "            \n",
    "            return json.dumps({\n",
    "                \"selected\": selected,\n",
    "                \"from_candidates\": candidates\n",
    "            })\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            return json.dumps({\n",
    "                \"error\": f\"Input JSON parsing error: {str(e)}\",\n",
    "                \"received_input\": query[:200]\n",
    "            })\n",
    "        except Exception as e:\n",
    "            return json.dumps({\n",
    "                \"error\": f\"Unexpected error: {str(e)}\",\n",
    "                \"type\": type(e).__name__\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c024b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TOOL WRAPPER CLASS\n",
    "# ============================================================================\n",
    "\n",
    "class Tool:\n",
    "    \"\"\"Wrapper for callable functions used by ReAct Agent\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, func: callable, description: str):\n",
    "        self.name = name\n",
    "        self.func = func\n",
    "        self.description = description\n",
    "    \n",
    "    def run(self, **kwargs):\n",
    "        try:\n",
    "            if 'query' in kwargs:\n",
    "                return self.func(kwargs['query'])\n",
    "            elif 'candidate_name' in kwargs:\n",
    "                return self.func(kwargs['candidate_name'])\n",
    "            else:\n",
    "                return self.func(list(kwargs.values())[0])\n",
    "        except Exception as e:\n",
    "            return json.dumps({\"error\": f\"Tool {self.name} failed: {str(e)}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fbd446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Revised ReActAgent with Query-to-Candidate Mapping and Score Ranking\n",
    "\n",
    "# ## Updated Implementation\n",
    "\n",
    "# This version tracks:\n",
    "# 1. Which original company name from the query maps to which database companies\n",
    "# 2. The matching scores for each candidate\n",
    "# 3. Ranking by score for each query term\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "@dataclass\n",
    "class CompanyMatch:\n",
    "    \"\"\"Represents a matched company with metadata\"\"\"\n",
    "    query_term: str           # Original term from query (e.g., \"Millenium\")\n",
    "    company_name: str         # Matched company from database\n",
    "    match_method: str         # 'nickname', 'disambiguate', 'fuzzy', 'exact'\n",
    "    score: float             # Confidence/similarity score\n",
    "    metadata: Dict = None    # Additional info\n",
    "\n",
    "\n",
    "class ReActAgent:\n",
    "    \"\"\"ReAct Agent for company name resolution with query-candidate mapping\"\"\"\n",
    "    \n",
    "    SYSTEM_PROMPT = \"\"\"You are a company name resolution agent specializing in the financial domain. \n",
    "                Your task is to identify names of financial institutions \n",
    "                (e.g., asset management firms, hedge funds, investment companies, financial institutions) \n",
    "                in user queries and map them to their official names in our database.\n",
    "\n",
    "                **Available Tools:**\n",
    "                1. extract_names[query] - Extract company names with spelling corrections and expansions. Returns each company with an ordered list of variants: [original, corrected, expanded]\n",
    "                2. map_nickname[name] - Check if a name is a nickname/shorthand (returns official name immediately if found)\n",
    "                3. fuzzy_search[name] - Find similar company names using fuzzy matching (includes similarity scores)\n",
    "                4. disambiguate[json_data] - Disambiguate between multiple candidates (required when fuzzy_search returns multiple matches)\n",
    "\n",
    "                **CRITICAL: Action Format**\n",
    "                All actions MUST use square brackets: Action: tool_name[input]\n",
    "                Examples:\n",
    "                - Action: extract_names[What is the balance of Apple?]\n",
    "                - Action: map_nickname[2sigma]\n",
    "                - Action: fuzzy_search[Millenia]\n",
    "                - Action: disambiguate[{\"candidates\": [\"Company A\", \"Company B\"], \"query\": \"term\"}]\n",
    "\n",
    "\n",
    "                **Required Workflow:**\n",
    "                1. **Extract ALL company names** from the query using extract_names (may return multiple companies)\n",
    "                2. **For EACH extracted company** (process each one separately):\n",
    "                   a. **Check nicknames in order**: Try map_nickname on original → corrected → expanded\n",
    "                   b. If ANY variant is a nickname → record the official name and move to next company\n",
    "                   c. If NONE are nicknames → proceed to fuzzy_search for this company\n",
    "                3. **For EACH company using fuzzy_search**:\n",
    "                   a. Try fuzzy_search with original → corrected → expanded until you get matches\n",
    "                   b. **If fuzzy_search returns 2+ matches** → MUST call disambiguate for THIS company\n",
    "                   c. Record the disambiguated result and move to next company\n",
    "                4. **After processing ALL companies** → Signal completion with \"COMPANIES_RESOLVED\"\n",
    "\n",
    "                **IMPORTANT: When map_nickname returns multiple companies:**\n",
    "                - This means the nickname represents an entity block (e.g., \"Millennium\" → multiple companies)\n",
    "                - You do NOT need to pick one - the system will automatically include ALL of them\n",
    "                - Simply note that the nickname was resolved and move to the next company\n",
    "\n",
    "                **Critical Notes:**\n",
    "                - Process EACH company independently - don't skip any\n",
    "                - If query has 3 companies, you must resolve all 3 (nickname check OR fuzzy search for each)\n",
    "                - Disambiguate is called PER COMPANY when that company has multiple fuzzy matches\n",
    "                - Keep track of all companies found and ensure each gets resolved\n",
    "\n",
    "                **Why check all nickname variants:**\n",
    "                - Original might be a nickname (e.g., \"2sigma\")\n",
    "                - Corrected might be a nickname (e.g., \"aapl\")\n",
    "                - Expanded might be a nickname (e.g., full name that maps to official)\n",
    "                - Checking variants ensures we don't miss direct mappings\n",
    "\n",
    "                **Fuzzy Search Strategy (only if NO nickname match found for a company):**\n",
    "                - Try variants in order: original → corrected → expanded\n",
    "                - Stop when you get good matches for THIS company\n",
    "                - If multiple matches returned, MUST call disambiguate for THIS company\n",
    "                - Format for disambiguate: {\"candidates\": [matches for THIS company], \"query\": \"this company's original search term\"}\n",
    "\n",
    "                **When to use disambiguate:**\n",
    "                - ALWAYS use it when fuzzy_search returns 2 or more matches FOR A COMPANY\n",
    "                - Called separately for each company that has multiple matches\n",
    "                - Format: {\"candidates\": [\"Company A\", \"Company B\", ...], \"query\": \"this specific company's search term\"}\n",
    "                - This determines if user meant all companies (ambiguous) or specific ones\n",
    "\n",
    "                **Output Format:**\n",
    "                Thought: [Your reasoning about what to do next]\n",
    "                Action: tool_name[input_value]\n",
    "\n",
    "                After receiving Observation:\n",
    "                Thought: [Your reasoning based on the observation]\n",
    "                Action: tool_name[input_value]\n",
    "\n",
    "                OR when you have resolved all companies:\n",
    "                Thought: I have resolved all companies from the query\n",
    "                Answer: COMPANIES_RESOLVED\n",
    "\n",
    "                **Important:**\n",
    "                - ALWAYS use square brackets [] for actions, never parentheses or just curly braces\n",
    "                - When done, simply return \"Answer: COMPANIES_RESOLVED\"\n",
    "                - The system will automatically collect ALL companies from your tool calls WITH SCORES\n",
    "                - Process EACH company in the query independently\n",
    "                - Check ALL nickname variants (original, corrected, expanded) BEFORE fuzzy search\n",
    "                - Always disambiguate when multiple fuzzy matches found PER COMPANY\n",
    "                - If no match for a company, note it but continue\"\"\"\n",
    "                        \n",
    "    def __init__(self, client: OpenAI, tools: List[Tool]):\n",
    "        self.client = client\n",
    "        self.tools_map = {tool.name: tool for tool in tools}\n",
    "        self.messages = []\n",
    "        self.tool_call_regex = r\"Action:\\s*(\\w+)\\[(.+)\\]\"\n",
    "        self.tool_history = []\n",
    "        self.extracted_companies = []  # NEW: Store extracted company names\n",
    "    \n",
    "    def run(self, query: str, verbose: bool = True) -> str:\n",
    "        \"\"\"Run the ReAct loop to resolve company names\"\"\"\n",
    "        self.messages = [\n",
    "            {\"role\": \"system\", \"content\": self.SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": f\"User Query: {query}\"}\n",
    "        ]\n",
    "        self.tool_history = []\n",
    "        self.extracted_companies = []\n",
    "        \n",
    "        for i in range(Config.MAX_ITERATIONS):\n",
    "            if verbose:\n",
    "                print(f\"\\n{'='*60}\")\n",
    "                print(f\"ITERATION {i+1}\")\n",
    "                print('='*60)\n",
    "            \n",
    "            # Get LLM response\n",
    "            response = self._get_completion()\n",
    "            if verbose:\n",
    "                print(f\"\\nAgent Response:\\n{response}\")\n",
    "            \n",
    "            # Check for final answer\n",
    "            if \"Answer:\" in response:\n",
    "                answer_text = response.split(\"Answer:\", 1)[1].strip()\n",
    "                \n",
    "                # Construct programmatic answer with mappings\n",
    "                if \"COMPANIES_RESOLVED\" in answer_text or True:  # Always use programmatic\n",
    "                    result = self._build_structured_result()\n",
    "                    \n",
    "                    if verbose:\n",
    "                        print(f\"\\n{'='*60}\")\n",
    "                        print(f\"STRUCTURED RESULT:\")\n",
    "                        print('='*60)\n",
    "                        for query_term, matches in result.items():\n",
    "                            print(f\"\\n'{query_term}' →\")\n",
    "                            for match in matches:\n",
    "                                print(f\"  - {match.company_name} (score: {match.score:.3f}, method: {match.match_method})\")\n",
    "                        print(f\"\\n{'='*60}\")\n",
    "                        print(f\"FINAL ANSWER: {self._format_final_answer(result)}\")\n",
    "                        print('='*60)\n",
    "                    \n",
    "                    return self._format_final_answer(result)\n",
    "            \n",
    "            # Check for action\n",
    "            action_match = re.search(self.tool_call_regex, response, re.DOTALL)\n",
    "            if action_match:\n",
    "                tool_name, tool_input = action_match.groups()\n",
    "                tool_input = tool_input.strip()\n",
    "                \n",
    "                if tool_name not in self.tools_map:\n",
    "                    observation = json.dumps({\"error\": f\"Unknown tool '{tool_name}'\"})\n",
    "                else:\n",
    "                    if verbose:\n",
    "                        print(f\"\\n→ Executing: {tool_name}[{tool_input}]\")\n",
    "                    observation = self._execute_tool(tool_name, tool_input)\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"→ Observation: {observation}\")\n",
    "                \n",
    "                # Record tool call in history\n",
    "                self.tool_history.append({\n",
    "                    \"tool\": tool_name,\n",
    "                    \"input\": tool_input,\n",
    "                    \"observation\": observation\n",
    "                })\n",
    "                \n",
    "                # Track extracted companies\n",
    "                if tool_name == \"extract_names\":\n",
    "                    try:\n",
    "                        data = json.loads(observation)\n",
    "                        companies = data.get(\"companies\", [])\n",
    "                        for company_data in companies:\n",
    "                            self.extracted_companies.append({\n",
    "                                \"original\": company_data.get(\"original\"),\n",
    "                                \"variants\": company_data.get(\"variants\", [])\n",
    "                            })\n",
    "                    except:\n",
    "                        pass\n",
    "                \n",
    "                self.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "                self.messages.append({\"role\": \"user\", \"content\": f\"Observation: {observation}\"})\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(\"\\n⚠ No valid Action found\")\n",
    "                self.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "        \n",
    "        # Even if max iterations reached, try to extract companies\n",
    "        result = self._build_structured_result()\n",
    "        return self._format_final_answer(result)\n",
    "    \n",
    "    def _build_structured_result(self) -> Dict[str, List[CompanyMatch]]:\n",
    "        \"\"\"\n",
    "        Build structured mapping of query terms to matched companies with scores.\n",
    "        \n",
    "        Returns:\n",
    "            Dict mapping original query terms to lists of CompanyMatch objects,\n",
    "            sorted by score (descending)\n",
    "        \"\"\"\n",
    "        # Map query term → list of CompanyMatch objects\n",
    "        query_to_matches: Dict[str, List[CompanyMatch]] = {}\n",
    "        \n",
    "        # Track which tool calls belong to which extracted company\n",
    "        current_query_term = None\n",
    "        \n",
    "        for tool_call in self.tool_history:\n",
    "            tool_name = tool_call[\"tool\"]\n",
    "            tool_input = tool_call[\"input\"]\n",
    "            observation = tool_call[\"observation\"]\n",
    "            \n",
    "            try:\n",
    "                result_data = json.loads(observation)\n",
    "                \n",
    "                # Determine which query term this tool call is for\n",
    "                # Match tool_input against extracted company variants\n",
    "                for extracted in self.extracted_companies:\n",
    "                    variants = extracted.get(\"variants\", [])\n",
    "                    if any(tool_input.lower().strip() == v.lower().strip() for v in variants):\n",
    "                        current_query_term = extracted.get(\"original\")\n",
    "                        break\n",
    "                \n",
    "                if not current_query_term:\n",
    "                    # Fallback: use the tool input itself as query term\n",
    "                    current_query_term = tool_input\n",
    "                \n",
    "                # Initialize list for this query term if not exists\n",
    "                if current_query_term not in query_to_matches:\n",
    "                    query_to_matches[current_query_term] = []\n",
    "                \n",
    "                # Extract from map_nickname (entity blocks)\n",
    "                if tool_name == \"map_nickname\" and result_data.get(\"is_nickname\"):\n",
    "                    official_names = result_data.get(\"official_names\", [])\n",
    "                    \n",
    "                    # Handle both list and single string\n",
    "                    if isinstance(official_names, list):\n",
    "                        names_list = official_names\n",
    "                    elif isinstance(official_names, str):\n",
    "                        names_list = [official_names]\n",
    "                    else:\n",
    "                        names_list = []\n",
    "                    \n",
    "                    for name in names_list:\n",
    "                        match = CompanyMatch(\n",
    "                            query_term=current_query_term,\n",
    "                            company_name=name,\n",
    "                            match_method='nickname',\n",
    "                            score=1.0,  # Perfect match for nicknames\n",
    "                            metadata={'count': len(names_list)}\n",
    "                        )\n",
    "                        query_to_matches[current_query_term].append(match)\n",
    "                \n",
    "                # Extract from fuzzy_search with scores\n",
    "                elif tool_name == \"fuzzy_search\":\n",
    "                    matches = result_data.get(\"matches\", [])\n",
    "                    for match_data in matches:\n",
    "                        company_name = match_data.get(\"company_name\")\n",
    "                        similarity_score = match_data.get(\"similarity_score\", 0.0)\n",
    "                        \n",
    "                        if company_name:\n",
    "                            match = CompanyMatch(\n",
    "                                query_term=current_query_term,\n",
    "                                company_name=company_name,\n",
    "                                match_method='fuzzy',\n",
    "                                score=similarity_score,\n",
    "                                metadata={'fuzzy_rank': len(query_to_matches[current_query_term])}\n",
    "                            )\n",
    "                            query_to_matches[current_query_term].append(match)\n",
    "                \n",
    "                # Extract from disambiguate (overrides fuzzy_search)\n",
    "                elif tool_name == \"disambiguate\":\n",
    "                    selected = result_data.get(\"selected\", [])\n",
    "                    \n",
    "                    if isinstance(selected, list):\n",
    "                        # Remove previous fuzzy matches for this query term\n",
    "                        # (disambiguate refines the fuzzy results)\n",
    "                        query_to_matches[current_query_term] = []\n",
    "                        \n",
    "                        for name in selected:\n",
    "                            match = CompanyMatch(\n",
    "                                query_term=current_query_term,\n",
    "                                company_name=name,\n",
    "                                match_method='disambiguate',\n",
    "                                score=0.9,  # High confidence for disambiguated results\n",
    "                                metadata={'from_candidates': result_data.get('from_candidates', [])}\n",
    "                            )\n",
    "                            query_to_matches[current_query_term].append(match)\n",
    "            \n",
    "            except (json.JSONDecodeError, AttributeError, KeyError) as e:\n",
    "                # Skip malformed observations\n",
    "                continue\n",
    "        \n",
    "        # Sort matches by score (descending) for each query term\n",
    "        for query_term in query_to_matches:\n",
    "            query_to_matches[query_term].sort(key=lambda x: x.score, reverse=True)\n",
    "        \n",
    "        return query_to_matches\n",
    "    \n",
    "    def _format_final_answer(self, structured_result: Dict[str, List[CompanyMatch]]) -> str:\n",
    "        \"\"\"Format the structured result as a simple comma-separated list\"\"\"\n",
    "        all_companies = []\n",
    "        seen = set()\n",
    "        \n",
    "        # Collect all companies (maintaining score order per query term)\n",
    "        for query_term, matches in structured_result.items():\n",
    "            for match in matches:\n",
    "                if match.company_name not in seen:\n",
    "                    all_companies.append(match.company_name)\n",
    "                    seen.add(match.company_name)\n",
    "        \n",
    "        return \", \".join(all_companies) if all_companies else \"No companies found\"\n",
    "    \n",
    "    def get_structured_result(self) -> Dict[str, List[CompanyMatch]]:\n",
    "        \"\"\"\n",
    "        Get the structured result with full mapping information.\n",
    "        Call this after run() to get detailed results.\n",
    "        \"\"\"\n",
    "        return self._build_structured_result()\n",
    "    \n",
    "    def _get_completion(self) -> str:\n",
    "        \"\"\"Get completion from OpenAI API\"\"\"\n",
    "        completion = self.client.chat.completions.create(\n",
    "            model=Config.OPENAI_MODEL,\n",
    "            messages=self.messages,\n",
    "            temperature=0.0\n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "    \n",
    "    def _execute_tool(self, tool_name: str, tool_input: str) -> str:\n",
    "        \"\"\"Execute a tool with the given input\"\"\"\n",
    "        tool = self.tools_map[tool_name]\n",
    "        tool_input = tool_input.strip('\"\\'')\n",
    "\n",
    "        if tool_name in [\"extract_names\", \"disambiguate\"]:\n",
    "            return tool.run(query=tool_input)\n",
    "        else:\n",
    "            return tool.run(candidate_name=tool_input)\n",
    "\n",
    "\n",
    "# ## Usage Example\n",
    "\n",
    "# ```python\n",
    "# # Initialize agent\n",
    "# agent = initialize_agent()\n",
    "\n",
    "# # Run query\n",
    "# result = agent.run(\"What is the client balance of Millenium and Bridge?\")\n",
    "\n",
    "# # Get simple answer\n",
    "# print(f\"Answer: {result}\")\n",
    "# # → \"Millennium Partners, Millennium Management LLC, Bridge Associates\"\n",
    "\n",
    "# # Get detailed structured result\n",
    "# structured = agent.get_structured_result()\n",
    "\n",
    "# # Access detailed information\n",
    "# for query_term, matches in structured.items():\n",
    "#     print(f\"\\nQuery term: '{query_term}'\")\n",
    "#     for match in matches:\n",
    "#         print(f\"  → {match.company_name}\")\n",
    "#         print(f\"     Score: {match.score:.3f}\")\n",
    "#         print(f\"     Method: {match.match_method}\")\n",
    "# # ```\n",
    "\n",
    "# ## Example Output\n",
    "\n",
    "# ```\n",
    "# Query term: 'Millenium'\n",
    "#   → Millennium Partners\n",
    "#      Score: 1.000\n",
    "#      Method: nickname\n",
    "#   → Millennium Management LLC\n",
    "#      Score: 1.000\n",
    "#      Method: nickname\n",
    "\n",
    "# Query term: 'Bridge'\n",
    "#   → Bridge Associates\n",
    "#      Score: 1.000\n",
    "#      Method: nickname\n",
    "\n",
    "# FINAL ANSWER: Millennium Partners, Millennium Management LLC, Bridge Associates\n",
    "# ```\n",
    "\n",
    "# ## Key Features\n",
    "\n",
    "# 1. **Query-to-Candidate Mapping**: Each original term is mapped to its matched companies\n",
    "# 2. **Score Tracking**: Maintains similarity/confidence scores from fuzzy_search and assigns perfect scores (1.0) to nickname matches\n",
    "# 3. **Method Tracking**: Records how each match was found (nickname, fuzzy, disambiguate)\n",
    "# 4. **Score Ranking**: Matches are sorted by score for each query term\n",
    "# 5. **Metadata**: Additional context like entity block size, fuzzy rank, etc.\n",
    "\n",
    "# This gives you full visibility into how each company was matched!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23e80b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # REACT AGENT\n",
    "\n",
    "\n",
    "# class ReActAgent:\n",
    "#     \"\"\"ReAct Agent for company name resolution with programmatic answer construction\"\"\"\n",
    "    \n",
    "#     SYSTEM_PROMPT = \"\"\"You are a company name resolution agent specializing in the financial domain. \n",
    "#                 Your task is to identify names of financial institutions \n",
    "#                 (e.g., asset management firms, hedge funds, investment companies, financial institutions) \n",
    "#                 in user queries and map them to their official names in our database.\n",
    "                \n",
    "#                 **Available Tools:**\n",
    "#                 1. extract_names[query] - Extract company names with spelling corrections and expansions. Returns each company with an ordered list of variants: [original, corrected, expanded]\n",
    "#                 2. map_nickname[name] - For each company name in the ordered list of variants, including the original, check if a company name is a nickname/shorthand (returns official name immediately if found)\n",
    "#                 3. fuzzy_search[name] - If there are no matches, for each company name in the ordered list of variants, find similar company names using fuzzy matching\n",
    "#                 4. disambiguate[json_data] - Disambiguate between multiple candidates (required when fuzzy_search returns multiple matches)\n",
    "\n",
    "#                 **CRITICAL: Action Format**\n",
    "#                 All actions MUST use square brackets: Action: tool_name[input]\n",
    "#                 Examples:\n",
    "#                 - Action: extract_names[What is the balance of Apple?]\n",
    "#                 - Action: map_nickname[2sigma]\n",
    "#                 - Action: fuzzy_search[Millenia]\n",
    "#                 - Action: disambiguate[{\"candidates\": [\"Company A\", \"Company B\"], \"query\": \"term\"}]\n",
    "\n",
    "\n",
    "#                 **Required Workflow:**\n",
    "#                 1. **Extract ALL company names** from the query using extract_names (may return multiple companies)\n",
    "#                 2. **For EACH extracted company** (process each one separately):\n",
    "#                    a. **Check nicknames in order**: Try map_nickname on original → corrected → expanded\n",
    "#                    b. If ANY variant is a nickname → record the official name and move to next company\n",
    "#                    c. If NONE are nicknames → proceed to fuzzy_search for this company\n",
    "#                 3. **For EACH company using fuzzy_search**:\n",
    "#                    a. Try fuzzy_search with original → corrected → expanded until you get matches\n",
    "#                    b. **If fuzzy_search returns 2+ matches** → MUST call disambiguate for THIS company\n",
    "#                    c. Record the disambiguated result and move to next company\n",
    "#                 4. **After processing ALL companies** → Signal completion with \"COMPANIES_RESOLVED\"\n",
    "\n",
    "#                 **IMPORTANT: When map_nickname returns multiple companies:**\n",
    "#                 - This means the nickname represents an entity block (e.g., \"Millennium\" → multiple companies)\n",
    "#                 - You do NOT need to pick one - the system will automatically include ALL of them\n",
    "#                 - Simply note that the nickname was resolved and move to the next company\n",
    "\n",
    "#                 **Critical Notes:**\n",
    "#                 - Process EACH company independently - don't skip any\n",
    "#                 - If query has 3 companies, you must resolve all 3 (nickname check OR fuzzy search for each)\n",
    "#                 - Disambiguate is called PER COMPANY when that company has multiple fuzzy matches\n",
    "#                 - Keep track of all companies found and ensure each gets resolved\n",
    "\n",
    "#                 **Why check all nickname variants:**\n",
    "#                 - Original might be a nickname (e.g., \"2sigma\")\n",
    "#                 - Corrected might be a nickname (e.g., \"aapl\")\n",
    "#                 - Expanded might be a nickname (e.g., full name that maps to official)\n",
    "#                 - Checking variants ensures we don't miss direct mappings\n",
    "\n",
    "#                 **Fuzzy Search Strategy (only if NO nickname match found for a company):**\n",
    "#                 - Try variants in order: original → corrected → expanded\n",
    "#                 - Stop when you get good matches for THIS company\n",
    "#                 - If multiple matches returned, MUST call disambiguate for THIS company\n",
    "#                 - Format for disambiguate: {\"candidates\": [matches for THIS company], \"query\": \"this company's original search term\"}\n",
    "\n",
    "#                 **When to use disambiguate:**\n",
    "#                 - ALWAYS use it when fuzzy_search returns 2 or more matches FOR A COMPANY\n",
    "#                 - Called separately for each company that has multiple matches\n",
    "#                 - Format: {\"candidates\": [\"Company A\", \"Company B\", ...], \"query\": \"this specific company's search term\"}\n",
    "#                 - This determines if user meant all companies (ambiguous) or specific ones\n",
    "\n",
    "#                 **Output Format:**\n",
    "#                 Thought: [Your reasoning about what to do next]\n",
    "#                 Action: tool_name[input_value]\n",
    "\n",
    "#                 After receiving Observation:\n",
    "#                 Thought: [Your reasoning based on the observation]\n",
    "#                 Action: tool_name[input_value]\n",
    "\n",
    "#                 OR when you have resolved all companies:\n",
    "#                 Thought: I have resolved all companies from the query\n",
    "#                 Answer: COMPANIES_RESOLVED\n",
    "\n",
    "#                 **Important:**\n",
    "#                 - ALWAYS use square brackets [] for actions, never parentheses or just curly braces\n",
    "#                 - When done, simply return \"Answer: COMPANIES_RESOLVED\"\n",
    "#                 - The system will automatically collect ALL companies from your tool calls\n",
    "#                 - Process EACH company in the query independently\n",
    "#                 - Check ALL nickname variants (original, corrected, expanded) BEFORE fuzzy search\n",
    "#                 - Always disambiguate when multiple fuzzy matches found PER COMPANY\n",
    "#                 - If no match for a company, note it but continue\"\"\"\n",
    "                        \n",
    "#     def __init__(self, client: OpenAI, tools: List[Tool]):\n",
    "#         self.client = client\n",
    "#         self.tools_map = {tool.name: tool for tool in tools}\n",
    "#         self.messages = []\n",
    "#         self.tool_call_regex = r\"Action:\\s*(\\w+)\\[(.+)\\]\"\n",
    "#         self.tool_history = []  # NEW: Track all tool calls\n",
    "    \n",
    "#     def run(self, query: str, verbose: bool = True) -> str:\n",
    "#         \"\"\"Run the ReAct loop to resolve company names\"\"\"\n",
    "#         self.messages = [\n",
    "#             {\"role\": \"system\", \"content\": self.SYSTEM_PROMPT},\n",
    "#             {\"role\": \"user\", \"content\": f\"User Query: {query}\"}\n",
    "#         ]\n",
    "#         self.tool_history = []  # Reset history for each run\n",
    "        \n",
    "#         for i in range(Config.MAX_ITERATIONS):\n",
    "#             if verbose:\n",
    "#                 print(f\"\\n{'='*60}\")\n",
    "#                 print(f\"ITERATION {i+1}\")\n",
    "#                 print('='*60)\n",
    "            \n",
    "#             # Get LLM response\n",
    "#             response = self._get_completion()\n",
    "#             if verbose:\n",
    "#                 print(f\"\\nAgent Response:\\n{response}\")\n",
    "            \n",
    "#             # Check for final answer\n",
    "#             if \"Answer:\" in response:\n",
    "#                 answer_text = response.split(\"Answer:\", 1)[1].strip()\n",
    "                \n",
    "#                 # NEW: If answer is the signal, construct programmatic answer\n",
    "#                 if \"COMPANIES_RESOLVED\" in answer_text:\n",
    "#                     final_companies = self._extract_all_companies_from_history()\n",
    "#                     answer = \", \".join(final_companies) if final_companies else \"No companies found\"\n",
    "                    \n",
    "#                     if verbose:\n",
    "#                         print(f\"\\n{'='*60}\")\n",
    "#                         print(f\"FINAL ANSWER (from tool history): {answer}\")\n",
    "#                         print('='*60)\n",
    "#                     return answer\n",
    "#                 else:\n",
    "#                     # Fallback: use LLM's answer but post-process it\n",
    "#                     final_companies = self._extract_all_companies_from_history()\n",
    "#                     if final_companies:\n",
    "#                         answer = \", \".join(final_companies)\n",
    "#                     else:\n",
    "#                         answer = answer_text\n",
    "                    \n",
    "#                     if verbose:\n",
    "#                         print(f\"\\n{'='*60}\")\n",
    "#                         print(f\"FINAL ANSWER: {answer}\")\n",
    "#                         print('='*60)\n",
    "#                     return answer\n",
    "            \n",
    "#             # Check for action\n",
    "#             action_match = re.search(self.tool_call_regex, response, re.DOTALL)\n",
    "#             if action_match:\n",
    "#                 tool_name, tool_input = action_match.groups()\n",
    "#                 tool_input = tool_input.strip()\n",
    "                \n",
    "#                 if tool_name not in self.tools_map:\n",
    "#                     observation = json.dumps({\"error\": f\"Unknown tool '{tool_name}'\"})\n",
    "#                 else:\n",
    "#                     if verbose:\n",
    "#                         print(f\"\\n→ Executing: {tool_name}[{tool_input}]\")\n",
    "#                     observation = self._execute_tool(tool_name, tool_input)\n",
    "                \n",
    "#                 if verbose:\n",
    "#                     print(f\"→ Observation: {observation}\")\n",
    "                \n",
    "#                 # NEW: Record tool call in history\n",
    "#                 self.tool_history.append({\n",
    "#                     \"tool\": tool_name,\n",
    "#                     \"input\": tool_input,\n",
    "#                     \"observation\": observation\n",
    "#                 })\n",
    "                \n",
    "#                 self.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "#                 self.messages.append({\"role\": \"user\", \"content\": f\"Observation: {observation}\"})\n",
    "#             else:\n",
    "#                 if verbose:\n",
    "#                     print(\"\\n⚠ No valid Action found\")\n",
    "#                 self.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "        \n",
    "#         # NEW: Even if max iterations reached, try to extract companies\n",
    "#         final_companies = self._extract_all_companies_from_history()\n",
    "#         if final_companies:\n",
    "#             return \", \".join(final_companies)\n",
    "#         return \"Error: Max iterations reached without finding an answer.\"\n",
    "    \n",
    "#     def _extract_all_companies_from_history(self) -> List[str]:\n",
    "#         \"\"\"\n",
    "#         Extract all resolved companies from tool call history.\n",
    "#         This is the core of Option 4 - programmatically parse tool results.\n",
    "#         \"\"\"\n",
    "#         all_companies = []\n",
    "#         seen_companies = set()  # Avoid duplicates\n",
    "        \n",
    "#         for tool_call in self.tool_history:\n",
    "#             tool_name = tool_call[\"tool\"]\n",
    "#             observation = tool_call[\"observation\"]\n",
    "            \n",
    "#             try:\n",
    "#                 result_data = json.loads(observation)\n",
    "                \n",
    "#                 # Extract from map_nickname (entity blocks)\n",
    "#                 if tool_name == \"map_nickname\" and result_data.get(\"is_nickname\"):\n",
    "#                     official_names = result_data.get(\"official_names\", [])\n",
    "#                     # Support both list and single string (backward compatibility)\n",
    "#                     if isinstance(official_names, list):\n",
    "#                         for name in official_names:\n",
    "#                             if name not in seen_companies:\n",
    "#                                 all_companies.append(name)\n",
    "#                                 seen_companies.add(name)\n",
    "#                     elif isinstance(official_names, str):\n",
    "#                         if official_names not in seen_companies:\n",
    "#                             all_companies.append(official_names)\n",
    "#                             seen_companies.add(official_names)\n",
    "                \n",
    "#                 # Extract from disambiguate\n",
    "#                 elif tool_name == \"disambiguate\":\n",
    "#                     selected = result_data.get(\"selected\", [])\n",
    "#                     if isinstance(selected, list):\n",
    "#                         for name in selected:\n",
    "#                             if name not in seen_companies:\n",
    "#                                 all_companies.append(name)\n",
    "#                                 seen_companies.add(name)\n",
    "                \n",
    "#                 # Extract from fuzzy_search (if only 1 match, it's definitive)\n",
    "#                 elif tool_name == \"fuzzy_search\":\n",
    "#                     matches = result_data.get(\"matches\", [])\n",
    "#                     if len(matches) == 1:\n",
    "#                         company_name = matches[0].get(\"company_name\")\n",
    "#                         if company_name and company_name not in seen_companies:\n",
    "#                             all_companies.append(company_name)\n",
    "#                             seen_companies.add(company_name)\n",
    "#                     # If multiple matches but no disambiguate call followed,\n",
    "#                     # this means the agent didn't complete properly\n",
    "#                     # Don't include these to avoid ambiguity\n",
    "            \n",
    "#             except (json.JSONDecodeError, AttributeError, KeyError):\n",
    "#                 # Skip malformed observations\n",
    "#                 continue\n",
    "        \n",
    "#         return all_companies\n",
    "    \n",
    "#     def _get_completion(self) -> str:\n",
    "#         \"\"\"Get completion from OpenAI API\"\"\"\n",
    "#         completion = self.client.chat.completions.create(\n",
    "#             model=Config.OPENAI_MODEL,\n",
    "#             messages=self.messages,\n",
    "#             temperature=0.0\n",
    "#         )\n",
    "#         return completion.choices[0].message.content\n",
    "    \n",
    "#     def _execute_tool(self, tool_name: str, tool_input: str) -> str:\n",
    "#         \"\"\"Execute a tool with the given input\"\"\"\n",
    "#         tool = self.tools_map[tool_name]\n",
    "\n",
    "#         tool_input = tool_input.strip('\"\\'')\n",
    "\n",
    "#         if tool_name in [\"extract_names\", \"disambiguate\"]:\n",
    "#             return tool.run(query=tool_input)\n",
    "#         else:\n",
    "#             return tool.run(candidate_name=tool_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "557449aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MAIN INITIALIZATION\n",
    "# ============================================================================\n",
    "\n",
    "def initialize_agent():\n",
    "    \"\"\"Initialize the complete agent system\"\"\"\n",
    "    # Setup OpenAI client\n",
    "    api_key = os.getenv('OPENAI_API_KEY')\n",
    "    if not api_key:\n",
    "        raise ValueError(\"OPENAI_API_KEY not found in environment\")\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    print(\"✓ OpenAI client initialized\")\n",
    "    \n",
    "    # Initialize company database\n",
    "    df_companies = initialize_company_database()\n",
    "    print(f\"✓ Loaded {len(df_companies)} companies\")\n",
    "    \n",
    "    # Prepare data for fuzzy matcher\n",
    "    company_data = [(str(i), row['Company']) for i, row in df_companies.iterrows()]\n",
    "    \n",
    "    # Initialize fuzzy matcher\n",
    "    matcher = FastFuzzyMatcher(company_data)\n",
    "    print(\"✓ Fuzzy matcher initialized\")\n",
    "    \n",
    "    # Initialize tools\n",
    "    tools_impl = CompanyResolutionTools(client, matcher)\n",
    "    \n",
    "    tools = [\n",
    "        Tool(\"extract_names\", tools_impl.extract_names, \n",
    "             \"Extract company names with spelling correction and expansion variants\"),\n",
    "        Tool(\"map_nickname\", tools_impl.map_nickname, \n",
    "             \"Map nickname to official company name(s). \\\n",
    "               IMPORTANT: If this returns multiple companies, ALL of them must be included in the final answer.\"),\n",
    "        Tool(\"fuzzy_search\", tools_impl.fuzzy_search, \n",
    "             \"Find similar company names using fuzzy matching\"),\n",
    "        Tool(\"disambiguate\", tools_impl.disambiguate, \n",
    "             \"Disambiguate between multiple candidates and return the most likely candidates\"),\n",
    "    ]\n",
    "    \n",
    "    # Create agent\n",
    "    agent = ReActAgent(client=client, tools=tools)\n",
    "    print(\"✓ ReAct Agent initialized\\n\")\n",
    "    \n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc5c8b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ OpenAI client initialized\n",
      "✓ Loaded 11 companies\n",
      "✓ Fuzzy matcher initialized\n",
      "✓ ReAct Agent initialized\n",
      "\n",
      "\n",
      "############################################################\n",
      "QUERY: What is the client balance of Milenium and Bride Assoc.?\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "ITERATION 1\n",
      "============================================================\n",
      "\n",
      "Agent Response:\n",
      "Thought: I need to extract the company names \"Milenium\" and \"Bride Assoc.\" from the user query and process each one to find their official names. I will start by extracting the names.\n",
      "\n",
      "Action: extract_names[What is the client balance of Milenium and Bride Assoc.?]\n",
      "\n",
      "→ Executing: extract_names[What is the client balance of Milenium and Bride Assoc.?]\n",
      "→ Observation: {\"companies\": [{\"original\": \"Milenium\", \"variants\": [\"Milenium\", \"Millennium\", \"Millennium Corporation\"]}, {\"original\": \"Bride Assoc.\", \"variants\": [\"Bride Assoc.\", \"Bride Assoc\", \"Bride Associates\"]}], \"message\": \"Extracted 2 company name(s) with variants\"}\n",
      "\n",
      "============================================================\n",
      "ITERATION 2\n",
      "============================================================\n",
      "\n",
      "Agent Response:\n",
      "Thought: I have extracted two companies: \"Milenium\" with variants including \"Millennium\" and \"Bride Assoc.\" with variants including \"Bride Associates.\" I will now check for nicknames for each company starting with \"Milenium.\"\n",
      "\n",
      "Action: map_nickname[Milenium]\n",
      "\n",
      "→ Executing: map_nickname[Milenium]\n",
      "→ Observation: {\n",
      "  \"is_nickname\": false,\n",
      "  \"message\": \"'Milenium' is not a recognized nickname\"\n",
      "}\n",
      "\n",
      "============================================================\n",
      "ITERATION 3\n",
      "============================================================\n",
      "\n",
      "Agent Response:\n",
      "Thought: \"Milenium\" is not a recognized nickname, so I will proceed to check the next variant, which is \"Millennium.\"\n",
      "\n",
      "Action: map_nickname[Millennium]\n",
      "\n",
      "→ Executing: map_nickname[Millennium]\n",
      "→ Observation: {\"is_nickname\": true, \"nickname\": \"Millennium\", \"official_names\": [\"Millennium Partners\", \"Millennium Management LLC\"], \"message\": \"Mapped identifier 'Millennium' to '['Millennium Partners', 'Millennium Management LLC']'\"}\n",
      "\n",
      "============================================================\n",
      "ITERATION 4\n",
      "============================================================\n",
      "\n",
      "Agent Response:\n",
      "Thought: The name \"Millennium\" is recognized as a nickname and maps to \"Millennium Partners\" and \"Millennium Management LLC.\" I will now proceed to the next company, \"Bride Assoc.\"\n",
      "\n",
      "Action: map_nickname[Bride Assoc.]\n",
      "\n",
      "→ Executing: map_nickname[Bride Assoc.]\n",
      "→ Observation: {\n",
      "  \"is_nickname\": false,\n",
      "  \"message\": \"'Bride Assoc.' is not a recognized nickname\"\n",
      "}\n",
      "\n",
      "============================================================\n",
      "ITERATION 5\n",
      "============================================================\n",
      "\n",
      "Agent Response:\n",
      "Thought: \"Bride Assoc.\" is not a recognized nickname, so I will check the next variant, which is \"Bride Assoc\" (without the period).\n",
      "\n",
      "Action: map_nickname[Bride Assoc]\n",
      "\n",
      "→ Executing: map_nickname[Bride Assoc]\n",
      "→ Observation: {\n",
      "  \"is_nickname\": false,\n",
      "  \"message\": \"'Bride Assoc' is not a recognized nickname\"\n",
      "}\n",
      "\n",
      "============================================================\n",
      "ITERATION 6\n",
      "============================================================\n",
      "\n",
      "Agent Response:\n",
      "Thought: \"Bride Assoc\" is also not a recognized nickname. I will now check the last variant, which is \"Bride Associates.\"\n",
      "\n",
      "Action: map_nickname[Bride Associates]\n",
      "\n",
      "→ Executing: map_nickname[Bride Associates]\n",
      "→ Observation: {\n",
      "  \"is_nickname\": false,\n",
      "  \"message\": \"'Bride Associates' is not a recognized nickname\"\n",
      "}\n",
      "\n",
      "============================================================\n",
      "ITERATION 7\n",
      "============================================================\n",
      "\n",
      "Agent Response:\n",
      "Thought: None of the variants for \"Bride Assoc.\" are recognized as nicknames. I will now proceed to perform a fuzzy search for \"Bride Assoc.\" to find potential matches.\n",
      "\n",
      "Action: fuzzy_search[Bride Assoc.]\n",
      "\n",
      "→ Executing: fuzzy_search[Bride Assoc.]\n",
      "  [DEBUG] Searching for: 'Bride Assoc.'\n",
      "  [DEBUG] Min score threshold: 0.25\n",
      "  [DEBUG] Found 3 matches\n",
      "  [DEBUG] Top match: ('5', 'Bridge Associates', 0.5982641080147475)\n",
      "→ Observation: {\n",
      "  \"status\": \"success\",\n",
      "  \"query\": \"Bride Assoc.\",\n",
      "  \"total_matches\": 3,\n",
      "  \"matches\": [\n",
      "    {\n",
      "      \"company_id\": \"5\",\n",
      "      \"company_name\": \"Bridge Associates\",\n",
      "      \"similarity_score\": 0.598\n",
      "    },\n",
      "    {\n",
      "      \"company_id\": \"6\",\n",
      "      \"company_name\": \"Bridgewater Associates\",\n",
      "      \"similarity_score\": 0.459\n",
      "    },\n",
      "    {\n",
      "      \"company_id\": \"7\",\n",
      "      \"company_name\": \"Bridger Capital\",\n",
      "      \"similarity_score\": 0.41\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "============================================================\n",
      "ITERATION 8\n",
      "============================================================\n",
      "\n",
      "Agent Response:\n",
      "Thought: The fuzzy search for \"Bride Assoc.\" returned three matches: \"Bridge Associates,\" \"Bridgewater Associates,\" and \"Bridger Capital.\" Since there are multiple matches, I will need to disambiguate to determine which company the user meant.\n",
      "\n",
      "Action: disambiguate[{\"candidates\": [\"Bridge Associates\", \"Bridgewater Associates\", \"Bridger Capital\"], \"query\": \"Bride Assoc.\"}]\n",
      "\n",
      "→ Executing: disambiguate[{\"candidates\": [\"Bridge Associates\", \"Bridgewater Associates\", \"Bridger Capital\"], \"query\": \"Bride Assoc.\"}]\n",
      "  [DEBUG] LLM returned: '[\"Bridge Associates\"]'\n",
      "  [DEBUG] Cleaned result: '[\"Bridge Associates\"]'\n",
      "→ Observation: {\"selected\": [\"Bridge Associates\"], \"from_candidates\": [\"Bridge Associates\", \"Bridgewater Associates\", \"Bridger Capital\"]}\n",
      "\n",
      "============================================================\n",
      "ITERATION 9\n",
      "============================================================\n",
      "\n",
      "Agent Response:\n",
      "Thought: The disambiguation process has selected \"Bridge Associates\" as the intended company from the candidates. Now I have resolved both companies: \"Milenium\" to \"Millennium Partners\" and \"Millennium Management LLC,\" and \"Bride Assoc.\" to \"Bridge Associates.\" \n",
      "\n",
      "Answer: COMPANIES_RESOLVED\n",
      "\n",
      "============================================================\n",
      "STRUCTURED RESULT:\n",
      "============================================================\n",
      "\n",
      "'What is the client balance of Milenium and Bride Assoc.?' →\n",
      "\n",
      "'Milenium' →\n",
      "  - Millennium Partners (score: 1.000, method: nickname)\n",
      "  - Millennium Management LLC (score: 1.000, method: nickname)\n",
      "\n",
      "'Bride Assoc.' →\n",
      "  - Bridge Associates (score: 0.900, method: disambiguate)\n",
      "\n",
      "============================================================\n",
      "FINAL ANSWER: Millennium Partners, Millennium Management LLC, Bridge Associates\n",
      "============================================================\n",
      "\n",
      "Final Result: Millennium Partners, Millennium Management LLC, Bridge Associates\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# USAGE EXAMPLE\n",
    "# ============================================================================\n",
    "\n",
    "data = {\n",
    "    'Company': [\n",
    "        \"Apple Inc.\", \n",
    "        \"Two Sigma Investments, LP\", \n",
    "        \"Millennium Partners\", \n",
    "        \"Millennium Management LLC\", \n",
    "        \"WorldQuant Millennium Advisors\",\n",
    "        \"Bridge Associates\", \n",
    "        \"Bridgewater Associates\",\n",
    "        \"Bridger Capital\",\n",
    "        \"Curry's Retail Ltd.\",\n",
    "        \"Alphabet Inc.\",\n",
    "        \"Abu Dhabi Investment Authority\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize the agent\n",
    "    agent = initialize_agent()\n",
    "    \n",
    "    # Test queries\n",
    "    test_queries = [\n",
    "        \"What is the client balance of Milenium and Bride Assoc.?\",\n",
    "        # \"Show me data for 2sigma\",\n",
    "        # \"Compare Millennium and WorldQuant performance\",\n",
    "        # \"What about Bridgwater Associates?\"\n",
    "    ]\n",
    "    \n",
    "    # Run tests\n",
    "    for query in test_queries:\n",
    "        print(f\"\\n{'#'*60}\")\n",
    "        print(f\"QUERY: {query}\")\n",
    "        print('#'*60)\n",
    "        result = agent.run(query, verbose=True)\n",
    "        print(f\"\\nFinal Result: {result}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84943d22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba5ef2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
